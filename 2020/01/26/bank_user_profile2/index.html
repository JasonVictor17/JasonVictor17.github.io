<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/mouse32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/mouse16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="分析银行客户画像并预测是否会在该银行存款,本篇基于上一篇,使用Python进行模型建立,模型选择,参数优化,特征选择等。">
<meta property="og:type" content="article">
<meta property="og:title" content="银行客户画像分析2-机器学习 with Python">
<meta property="og:url" content="http://yoursite.com/2020/01/26/bank_user_profile2/index.html">
<meta property="og:site_name" content="Jingde&#39;s Blog">
<meta property="og:description" content="分析银行客户画像并预测是否会在该银行存款,本篇基于上一篇,使用Python进行模型建立,模型选择,参数优化,特征选择等。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2020/01/25/bank_user_profile2/output_24_0.png">
<meta property="og:image" content="http://yoursite.com/2020/01/25/bank_user_profile2/output_34_0.png">
<meta property="article:published_time" content="2020-01-25T19:13:35.000Z">
<meta property="article:modified_time" content="2020-01-27T13:20:39.286Z">
<meta property="article:author" content="Jason">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/01/25/bank_user_profile2/output_24_0.png">

<link rel="canonical" href="http://yoursite.com/2020/01/26/bank_user_profile2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>银行客户画像分析2-机器学习 with Python | Jingde's Blog</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?<061f7a05407b07f04642d8ffecfff900>";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jingde's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/26/bank_user_profile2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="A free place">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jingde's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          银行客户画像分析2-机器学习 with Python
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-26 03:13:35" itemprop="dateCreated datePublished" datetime="2020-01-26T03:13:35+08:00">2020-01-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-27 21:20:39" itemprop="dateModified" datetime="2020-01-27T21:20:39+08:00">2020-01-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">Python学习</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>分析银行客户画像并预测是否会在该银行存款,本篇基于上一篇,使用Python进行模型建立,模型选择,参数优化,特征选择等。</p>
<a id="more"></a>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import libraries necessary for this project</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display <span class="comment"># Allows the use of display() for DataFrames</span></span><br><span class="line"><span class="comment"># Import train_test_split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"processed_data1.csv"</span>)</span><br><span class="line">target = data[<span class="string">'target'</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = data.drop(<span class="string">'Unnamed: 0'</span>, axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features = data.drop(<span class="string">'target'</span>, axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="分训练集和测试集"><a href="#分训练集和测试集" class="headerlink" title="分训练集和测试集"></a>分训练集和测试集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split the 'features' and 'income' data into training and testing sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(features, </span><br><span class="line">                                                    target, </span><br><span class="line">                                                    test_size = <span class="number">0.2</span>, </span><br><span class="line">                                                    random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the results of the split</span></span><br><span class="line">print(<span class="string">"Training set has &#123;&#125; samples."</span>.format(X_train.shape[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"Testing set has &#123;&#125; samples."</span>.format(X_test.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>Training set has 32950 samples.
Testing set has 8238 samples.</code></pre><h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> fbeta_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_predict</span><span class="params">(learner, sample_size, X_train, y_train, X_test, y_test)</span>:</span> </span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    inputs:</span></span><br><span class="line"><span class="string">       - learner: the learning algorithm to be trained and predicted on</span></span><br><span class="line"><span class="string">       - sample_size: the size of samples (number) to be drawn from training set</span></span><br><span class="line"><span class="string">       - X_train: features training set</span></span><br><span class="line"><span class="string">       - y_train: income training set</span></span><br><span class="line"><span class="string">       - X_test: features testing set</span></span><br><span class="line"><span class="string">       - y_test: income testing set</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])</span></span><br><span class="line">    start = time() <span class="comment"># Get start time</span></span><br><span class="line">    learner = learner.fit(X_train[:sample_size:], y_train[:sample_size].values.ravel())</span><br><span class="line">    end = time() <span class="comment"># Get end time</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate the training time</span></span><br><span class="line">    results[<span class="string">'train_time'</span>] = end - start</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Get the predictions on the test set(X_test),</span></span><br><span class="line">    <span class="comment">#       then get predictions on the first 300 training samples(X_train) using .predict()</span></span><br><span class="line">    start = time() <span class="comment"># Get start time</span></span><br><span class="line">    predictions_test = learner.predict(X_test)</span><br><span class="line">    predictions_train = learner.predict(X_train[:<span class="number">300</span>])</span><br><span class="line">    end = time() <span class="comment"># Get end time</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate the total prediction time</span></span><br><span class="line">    results[<span class="string">'pred_time'</span>] = end - start</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Compute accuracy on the first 300 training samples which is y_train[:300]</span></span><br><span class="line">    results[<span class="string">'acc_train'</span>] = accuracy_score(y_train[:<span class="number">300</span>], predictions_train)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Compute accuracy on test set using accuracy_score()</span></span><br><span class="line">    results[<span class="string">'acc_test'</span>] = accuracy_score(y_test, predictions_test)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute F-score on the the first 300 training samples using fbeta_score()</span></span><br><span class="line">    results[<span class="string">'f_train'</span>] = fbeta_score(y_train[:<span class="number">300</span>], predictions_train, beta = <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Compute F-score on the test set which is y_test</span></span><br><span class="line">    results[<span class="string">'f_test'</span>] = fbeta_score(y_test, predictions_test, beta = <span class="number">0.5</span>)</span><br><span class="line">       </span><br><span class="line">    <span class="comment"># Success</span></span><br><span class="line">    print(<span class="string">"&#123;&#125; trained on &#123;&#125; samples."</span>.format(learner.__class__.__name__, sample_size))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Return the results</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import the three supervised learning models from sklearn</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.seed(<span class="number">2020</span>)</span><br><span class="line"><span class="comment"># Initialize the three models</span></span><br><span class="line">clf_A = LogisticRegression(solver = <span class="string">'liblinear'</span>) <span class="comment"># set the default value manually in order to get rid of warnings</span></span><br><span class="line">clf_B = RandomForestClassifier(n_estimators = <span class="number">100</span>) <span class="comment"># set the default value manually in order to get rid of warnings</span></span><br><span class="line">clf_C = KNeighborsClassifier() <span class="comment"># set the default value manually in order to get rid of warnings</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the number of samples for 1%, 10%, and 100% of the training data</span></span><br><span class="line">samples_100 = len(y_train)</span><br><span class="line">samples_10 = int(len(y_train)*<span class="number">0.1</span>)</span><br><span class="line">samples_1 = int(len(y_train)*<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Collect results on the learners</span></span><br><span class="line">results = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> clf <span class="keyword">in</span> [clf_A, clf_B, clf_C]:</span><br><span class="line">    clf_name = clf.__class__.__name__</span><br><span class="line">    results[clf_name] = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, samples <span class="keyword">in</span> enumerate([samples_1, samples_10, samples_100]):</span><br><span class="line">        results[clf_name][i] = \</span><br><span class="line">        train_predict(clf, samples, X_train, y_train, X_test, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>LogisticRegression trained on 329 samples.
LogisticRegression trained on 3295 samples.
LogisticRegression trained on 32950 samples.
RandomForestClassifier trained on 329 samples.
RandomForestClassifier trained on 3295 samples.
RandomForestClassifier trained on 32950 samples.
KNeighborsClassifier trained on 329 samples.
KNeighborsClassifier trained on 3295 samples.
KNeighborsClassifier trained on 32950 samples.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results</span><br></pre></td></tr></table></figure>




<pre><code>{&apos;LogisticRegression&apos;: {0: {&apos;train_time&apos;: 0.0019948482513427734,
   &apos;pred_time&apos;: 0.004987239837646484,
   &apos;acc_train&apos;: 0.8866666666666667,
   &apos;acc_test&apos;: 0.8869871327992231,
   &apos;f_train&apos;: 0.6201550387596898,
   &apos;f_test&apos;: 0.39245863793766833},
  1: {&apos;train_time&apos;: 0.01795196533203125,
   &apos;pred_time&apos;: 0.003989219665527344,
   &apos;acc_train&apos;: 0.86,
   &apos;acc_test&apos;: 0.8990046127700898,
   &apos;f_train&apos;: 0.4744525547445255,
   &apos;f_test&apos;: 0.4798698657991053},
  2: {&apos;train_time&apos;: 0.3007650375366211,
   &apos;pred_time&apos;: 0.003989219665527344,
   &apos;acc_train&apos;: 0.8533333333333334,
   &apos;acc_test&apos;: 0.8980335032774945,
   &apos;f_train&apos;: 0.42635658914728686,
   &apos;f_test&apos;: 0.45267489711934156}},
 &apos;RandomForestClassifier&apos;: {0: {&apos;train_time&apos;: 0.0638282299041748,
   &apos;pred_time&apos;: 0.0827479362487793,
   &apos;acc_train&apos;: 1.0,
   &apos;acc_test&apos;: 0.8874726875455208,
   &apos;f_train&apos;: 1.0,
   &apos;f_test&apos;: 0.35665914221218964},
  1: {&apos;train_time&apos;: 0.2373659610748291,
   &apos;pred_time&apos;: 0.10571742057800293,
   &apos;acc_train&apos;: 0.9966666666666667,
   &apos;acc_test&apos;: 0.8958485069191552,
   &apos;f_train&apos;: 0.9954751131221717,
   &apos;f_test&apos;: 0.4736275565123789},
  2: {&apos;train_time&apos;: 2.7166779041290283,
   &apos;pred_time&apos;: 0.16755199432373047,
   &apos;acc_train&apos;: 0.99,
   &apos;acc_test&apos;: 0.896091284292304,
   &apos;f_train&apos;: 0.9859154929577465,
   &apos;f_test&apos;: 0.47669868374244045}},
 &apos;KNeighborsClassifier&apos;: {0: {&apos;train_time&apos;: 0.0019948482513427734,
   &apos;pred_time&apos;: 0.3361320495605469,
   &apos;acc_train&apos;: 0.8833333333333333,
   &apos;acc_test&apos;: 0.888443797038116,
   &apos;f_train&apos;: 0.5982905982905984,
   &apos;f_test&apos;: 0.3638017280582083},
  1: {&apos;train_time&apos;: 0.007975578308105469,
   &apos;pred_time&apos;: 1.4731249809265137,
   &apos;acc_train&apos;: 0.88,
   &apos;acc_test&apos;: 0.8903860160233066,
   &apos;f_train&apos;: 0.5813953488372093,
   &apos;f_test&apos;: 0.430752453653217},
  2: {&apos;train_time&apos;: 0.4777207374572754,
   &apos;pred_time&apos;: 6.75963830947876,
   &apos;acc_train&apos;: 0.8633333333333333,
   &apos;acc_test&apos;: 0.8956057295460063,
   &apos;f_train&apos;: 0.5202312138728323,
   &apos;f_test&apos;: 0.47895997263085877}}}</code></pre><p>最好的是KNN,在训练所有训练集后,准确率达到89.6%,但是$F_{0.5}$ score 只有0.48,意味着在预测非存款对象的准确度远高于预测存款对象的准确度,这不利于我们找出潜在的存款对象,我们继续利用网格搜索来优化我们的参数和模型。</p>
<h3 id="其他数据集"><a href="#其他数据集" class="headerlink" title="其他数据集"></a>其他数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">i = [<span class="string">'2'</span>,<span class="string">'3'</span>,<span class="string">'4'</span>,<span class="string">'5'</span>]</span><br><span class="line">accuracy_all = []</span><br><span class="line">f_all = []</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> i:</span><br><span class="line">    data = pd.read_csv(<span class="string">"processed_data"</span>+ each +<span class="string">".csv"</span>)</span><br><span class="line">    target = data[<span class="string">'target'</span>]</span><br><span class="line">    data = data.drop(<span class="string">'Unnamed: 0'</span>, axis = <span class="number">1</span>)</span><br><span class="line">    features = data.drop(<span class="string">'target'</span>, axis = <span class="number">1</span>)</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(features, </span><br><span class="line">                                                        target, </span><br><span class="line">                                                        test_size = <span class="number">0.2</span>, </span><br><span class="line">                                                        random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    clf_C = KNeighborsClassifier()</span><br><span class="line">    learner = clf_C.fit(X_train, y_train.values.ravel())</span><br><span class="line">    predictions_test = learner.predict(X_test)</span><br><span class="line">    accuracy_all.append(accuracy_score(y_test, predictions_test))</span><br><span class="line">    f_all.append(fbeta_score(y_test, predictions_test, beta = <span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(accuracy_all)</span><br><span class="line">print(f_all)</span><br></pre></td></tr></table></figure>

<pre><code>[0.895241563486283, 0.8958485069191552, 0.8969410050983249, 0.8958485069191552]
[0.4761904761904762, 0.481064483111566, 0.48780487804878053, 0.47987616099071206]</code></pre><p>准确性和$F_{0.5}$ score 在不同数据集差不多,说明cart来填补缺失值的方法有一致性。</p>
<h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> make_scorer</span><br><span class="line">random.seed(<span class="number">42</span>)</span><br><span class="line"><span class="comment"># Initialize the classifier</span></span><br><span class="line">clf = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the parameters list you wish to tune, using a dictionary if needed.</span></span><br><span class="line">k_range = list(range(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line">parameters = &#123; <span class="string">'algorithm'</span> : [<span class="string">'auto'</span>,<span class="string">'ball_tree'</span>,<span class="string">'kd_tree'</span>,<span class="string">'brute'</span>], <span class="string">'weights'</span> : [<span class="string">'uniform'</span>,<span class="string">'distance'</span>], <span class="string">'n_neighbors'</span> : k_range&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make an fbeta_score scoring object using make_scorer()</span></span><br><span class="line">scorer = make_scorer(fbeta_score, beta = <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()</span></span><br><span class="line">grid_obj = GridSearchCV(clf, parameters, scoring=scorer, cv = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the grid search object to the training data and find the optimal parameters using fit()</span></span><br><span class="line">grid_fit = grid_obj.fit(X_train, y_train.values.ravel())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the estimator</span></span><br><span class="line">best_clf = grid_fit.best_estimator_</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions using the unoptimized and model</span></span><br><span class="line">predictions = (clf.fit(X_train, y_train.values.ravel())).predict(X_test)</span><br><span class="line">best_predictions = best_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Report the before-and-afterscores</span></span><br><span class="line">print(<span class="string">"Unoptimized model\n------"</span>)</span><br><span class="line">print(<span class="string">"Accuracy score on testing data: &#123;:.4f&#125;"</span>.format(accuracy_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">"F-score on testing data: &#123;:.4f&#125;"</span>.format(fbeta_score(y_test, predictions, beta = <span class="number">0.5</span>)))</span><br><span class="line">print(<span class="string">"\nOptimized Model\n------"</span>)</span><br><span class="line">print(<span class="string">"Final accuracy score on the testing data: &#123;:.4f&#125;"</span>.format(accuracy_score(y_test, best_predictions)))</span><br><span class="line">print(<span class="string">"Final F-score on the testing data: &#123;:.4f&#125;"</span>.format(fbeta_score(y_test, best_predictions, beta = <span class="number">0.5</span>)))</span><br><span class="line">print(<span class="string">'best params are:'</span>,str(grid_obj.best_params_))</span><br></pre></td></tr></table></figure>

<pre><code>Unoptimized model
------
Accuracy score on testing data: 0.8958
F-score on testing data: 0.4799

Optimized Model
------
Final accuracy score on the testing data: 0.8989
Final F-score on the testing data: 0.4920
best params are: {&apos;algorithm&apos;: &apos;brute&apos;, &apos;n_neighbors&apos;: 9, &apos;weights&apos;: &apos;uniform&apos;}</code></pre><h3 id="Cutoff-value"><a href="#Cutoff-value" class="headerlink" title="Cutoff value"></a>Cutoff value</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"processed_data5.csv"</span>)</span><br><span class="line">target = data[<span class="string">'target'</span>]</span><br><span class="line">data = data.drop(<span class="string">'Unnamed: 0'</span>, axis = <span class="number">1</span>)</span><br><span class="line">features = data.drop(<span class="string">'target'</span>, axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># accurate and f score in test set with cutoff = 0.5</span></span><br><span class="line">random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(features, </span><br><span class="line">                                                    target, </span><br><span class="line">                                                    test_size = <span class="number">0.1</span>, </span><br><span class="line">                                                    random_state = <span class="number">0</span>)</span><br><span class="line">X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">clf_C = KNeighborsClassifier(algorithm = <span class="string">'brute'</span>,n_neighbors = <span class="number">9</span>, weights = <span class="string">'uniform'</span>)</span><br><span class="line">learner = clf_C.fit(X_train, y_train.values.ravel())</span><br><span class="line">predictions_test = learner.predict(X_test)</span><br><span class="line">print(accuracy_score(y_test, predictions_test))</span><br><span class="line">print(fbeta_score(y_test, predictions_test, beta = <span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>

<pre><code>0.8990046127700898
0.4892086330935252</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">confusion_matrix(y_test, predictions_test) <span class="comment"># 默认cutoff为p = 0.5</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[3567,   98],
       [ 318,  136]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">predictions_test_p = learner.predict_proba(X_test)</span><br><span class="line">predictions_test_p=pd.DataFrame(predictions_test_p)[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 我们看到选取0.3 cutoff 真的1的预测数明显上升</span></span><br><span class="line">predictions_test_pfinal = predictions_test_p&gt;=<span class="number">0.3</span></span><br><span class="line">predictions_test_pfinal=predictions_test_pfinal.astype(int)</span><br><span class="line">confusion_matrix(y_test, predictions_test_pfinal)</span><br></pre></td></tr></table></figure>




<pre><code>array([[3377,  288],
       [ 230,  224]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找到最佳cutoff</span></span><br><span class="line">i = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">1</span>]</span><br><span class="line">accuracy_s = []</span><br><span class="line">f_s = []</span><br><span class="line">precision_s = []</span><br><span class="line">recall_s=[]</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> i:</span><br><span class="line">    predictions_test_pfinal = predictions_test_p&gt;=each</span><br><span class="line">    predictions_test_pfinal=predictions_test_pfinal.astype(int)</span><br><span class="line">    f_s.append(fbeta_score(y_test, predictions_test_pfinal, beta = <span class="number">1</span>))</span><br><span class="line">    accuracy_s.append(accuracy_score(y_test, predictions_test_pfinal))</span><br><span class="line">    precision_s.append(precision_score(y_test, predictions_test_pfinal))</span><br><span class="line">    recall_s.append(recall_score(y_test, predictions_test_pfinal))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(i,precision_s, color=<span class="string">'green'</span>, label=<span class="string">'precision'</span>)</span><br><span class="line">plt.plot(i,recall_s, color=<span class="string">'red'</span>, label=<span class="string">'recall'</span>)</span><br><span class="line">plt.plot(i,accuracy_s, color=<span class="string">'blue'</span>, label=<span class="string">'accuracy'</span>)</span><br><span class="line">plt.plot(i,f_s,color=<span class="string">'black'</span>,label=<span class="string">'F1 score'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">'cutoff value'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'rate'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/01/25/bank_user_profile2/output_24_0.png" alt="png"></p>
<p>根据图表我们可以看出在 cutoff value大致在0.33左右我们大致得到一个比较均衡的预测结果,如果我们要提高precision,也就是保证精准的找到愿意存款的人,那么我们可以选择较高的cutoff value来保持精准定位,但同时也会放弃更多的潜在的客户(节约成本),如果我们要提高recall,也就是希望覆盖更多的潜在客户,那么就要选择较低的cutoff value,这样成本会上升。</p>
<p>最后我们在验证集中验证我们的结论,我们先选择p=0.18</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># validation set</span></span><br><span class="line"></span><br><span class="line">predictions_val_p = learner.predict_proba(X_val)</span><br><span class="line">predictions_val_p=pd.DataFrame(predictions_val_p)[<span class="number">1</span>]</span><br><span class="line">predictions_val_pfinal = predictions_val_p&gt;=<span class="number">0.18</span></span><br><span class="line">predictions_val_pfinal=predictions_val_pfinal.astype(int)</span><br><span class="line">print(confusion_matrix(y_val, predictions_val_pfinal))</span><br><span class="line">print(recall_score(y_val, predictions_val_pfinal))</span><br><span class="line">print(precision_score(y_val, predictions_val_pfinal))</span><br></pre></td></tr></table></figure>

<pre><code>[[2724  542]
 [ 173  268]]
0.6077097505668935
0.3308641975308642</code></pre><p>可以发现在总共441位潜在客户里我们预测到了268位,达到了60.7%。但是我们预测的810位顾客里只有268位是正确的,精准度为33%。当然不使用模型的精准度为11.9%。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># validation set</span></span><br><span class="line">predictions_val_p = learner.predict_proba(X_val)</span><br><span class="line">predictions_val_p=pd.DataFrame(predictions_val_p)[<span class="number">1</span>]</span><br><span class="line">predictions_val_pfinal = predictions_val_p&gt;=<span class="number">0.8</span></span><br><span class="line">predictions_val_pfinal=predictions_val_pfinal.astype(int)</span><br><span class="line">print(confusion_matrix(y_val, predictions_val_pfinal))</span><br><span class="line">print(recall_score(y_val, predictions_val_pfinal))</span><br><span class="line">print(precision_score(y_val, predictions_val_pfinal))</span><br></pre></td></tr></table></figure>

<pre><code>[[3257    9]
 [ 419   22]]
0.049886621315192746
0.7096774193548387</code></pre><p>可以发现调高cutoff value后,我们的预测变得更加谨慎,在预测的31位潜在客户里有22位是真的潜在客户,达到了71%的正确率。但是覆盖面不够广,损失了大多数的潜在客户。</p>
<h3 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import a supervised learning model that has 'feature_importances_'</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the supervised model on the training set using .fit(X_train, y_train)</span></span><br><span class="line">param_dist = &#123;<span class="string">"max_depth"</span>: [<span class="number">3</span>, <span class="literal">None</span>],</span><br><span class="line">              <span class="string">"n_estimators"</span>: list(range(<span class="number">10</span>, <span class="number">200</span>)),</span><br><span class="line">              <span class="string">"max_features"</span>: list(range(<span class="number">1</span>, X_test.shape[<span class="number">1</span>]+<span class="number">1</span>)),</span><br><span class="line">              <span class="string">"min_samples_split"</span>: list(range(<span class="number">2</span>, <span class="number">11</span>)),</span><br><span class="line">              <span class="string">"min_samples_leaf"</span>: list(range(<span class="number">1</span>, <span class="number">11</span>)),</span><br><span class="line">              <span class="string">"bootstrap"</span>: [<span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">              <span class="string">"criterion"</span>: [<span class="string">"gini"</span>, <span class="string">"entropy"</span>]&#125;</span><br><span class="line">model = RandomizedSearchCV(clf_B, param_distributions=param_dist)</span><br><span class="line">model.fit(X_train, y_train.values.ravel())</span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> Extract the feature importances using .feature_importances_ </span></span><br><span class="line">importances = model.best_estimator_.feature_importances_</span><br></pre></td></tr></table></figure>

<pre><code>C:\Users\jasonguo\Anaconda3\lib\site-packages\sklearn\model_selection\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> pl</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_plot</span><span class="params">(importances, X_train, y_train)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Display the five most important features</span></span><br><span class="line">    indices = np.argsort(importances)[::<span class="number">-1</span>]</span><br><span class="line">    columns = X_train.columns.values[indices[:<span class="number">5</span>]]</span><br><span class="line">    values = importances[indices][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Creat the plot</span></span><br><span class="line">    fig = pl.figure(figsize = (<span class="number">9</span>,<span class="number">5</span>))</span><br><span class="line">    pl.title(<span class="string">"Normalized Weights for First Five Most Predictive Features"</span>, fontsize = <span class="number">16</span>)</span><br><span class="line">    pl.bar(np.arange(<span class="number">5</span>), values, width = <span class="number">0.6</span>, align=<span class="string">"center"</span>, color = <span class="string">'#00A000'</span>, \</span><br><span class="line">          label = <span class="string">"Feature Weight"</span>)</span><br><span class="line">    pl.bar(np.arange(<span class="number">5</span>) - <span class="number">0.3</span>, np.cumsum(values), width = <span class="number">0.2</span>, align = <span class="string">"center"</span>, color = <span class="string">'#00A0A0'</span>, \</span><br><span class="line">          label = <span class="string">"Cumulative Feature Weight"</span>)</span><br><span class="line">    pl.xticks(np.arange(<span class="number">5</span>), columns)</span><br><span class="line">    pl.xlim((<span class="number">-0.5</span>, <span class="number">4.5</span>))</span><br><span class="line">    pl.ylabel(<span class="string">"Weight"</span>, fontsize = <span class="number">12</span>)</span><br><span class="line">    pl.xlabel(<span class="string">"Feature"</span>, fontsize = <span class="number">12</span>)</span><br><span class="line">    </span><br><span class="line">    pl.legend(loc = <span class="string">'upper center'</span>)</span><br><span class="line">    pl.tight_layout()</span><br><span class="line">    pl.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_plot(importances, X_train, y_train)</span><br></pre></td></tr></table></figure>


<p><img src="/2020/01/25/bank_user_profile2/output_34_0.png" alt="png"></p>
<p>可以看到前五个重要的指标,第一个是雇佣员工数,第二个是欧洲银行间利率,第三个是年龄,第四个和第五个都是受访相关参数。私以为,机器学习和计量经济学的方法不同之处在于机器学习更加注重预测结果的准确性,而忽视了预测结果和参数直接的因果关系,这些因果关系是很难通过机器学习的一些方法被解释的,即使预测结果非常准确,但是一些参数可能和预测目标没有实际的相关性。接下来就使用计量经济学的方法来研究哪些因素可能导致用户存款。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reduce the feature space</span></span><br><span class="line">X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::<span class="number">-1</span>])[:<span class="number">5</span>]]]</span><br><span class="line">X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::<span class="number">-1</span>])[:<span class="number">5</span>]]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train on the "best" model found from grid search earlier</span></span><br><span class="line">clf = (clone(best_clf)).fit(X_train_reduced, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make new predictions</span></span><br><span class="line">reduced_predictions = clf.predict(X_test_reduced)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Report scores from the final model using both versions of data</span></span><br><span class="line">print(<span class="string">"Final Model trained on full data\n------"</span>)</span><br><span class="line">print(<span class="string">"Accuracy on testing data: &#123;:.4f&#125;"</span>.format(accuracy_score(y_test, best_predictions)))</span><br><span class="line">print(<span class="string">"F-score on testing data: &#123;:.4f&#125;"</span>.format(fbeta_score(y_test, best_predictions, beta = <span class="number">0.5</span>)))</span><br><span class="line">print(<span class="string">"\nFinal Model trained on reduced data\n------"</span>)</span><br><span class="line">print(<span class="string">"Accuracy on testing data: &#123;:.4f&#125;"</span>.format(accuracy_score(y_test, reduced_predictions)))</span><br><span class="line">print(<span class="string">"F-score on testing data: &#123;:.4f&#125;"</span>.format(fbeta_score(y_test, reduced_predictions, beta = <span class="number">0.5</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>Final Model trained on full data
------
Accuracy on testing data: 0.8989
F-score on testing data: 0.4920

Final Model trained on reduced data
------
Accuracy on testing data: 0.8934
F-score on testing data: 0.4420</code></pre><p>可以发现只取排名前五个参数的模型,F score 下降了一些, 意味着预测有存款意向的人的准确度变低了一些,但不是很多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="Jason 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/01/25/bank_user_profile/" rel="prev" title="银行客户画像分析1-数据预处理 with R">
      <i class="fa fa-chevron-left"></i> 银行客户画像分析1-数据预处理 with R
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/01/26/Hexo%20%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%8A%A0%E5%85%A5Rmarkdown%E7%94%9F%E6%88%90%E7%9A%84html%E6%96%87%E4%BB%B6/" rel="next" title="Hexo 如何优雅的加入Rmarkdown生成的html/pdf文件">
      Hexo 如何优雅的加入Rmarkdown生成的html/pdf文件 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80ODM1Ny8yNDg1MQ=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#分训练集和测试集"><span class="nav-number">1.</span> <span class="nav-text">分训练集和测试集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#建立模型"><span class="nav-number">2.</span> <span class="nav-text">建立模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练模型"><span class="nav-number">3.</span> <span class="nav-text">训练模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他数据集"><span class="nav-number">4.</span> <span class="nav-text">其他数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网格搜索"><span class="nav-number">5.</span> <span class="nav-text">网格搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cutoff-value"><span class="nav-number">6.</span> <span class="nav-text">Cutoff value</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Selection"><span class="nav-number">7.</span> <span class="nav-text">Feature Selection</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jason</p>
  <div class="site-description" itemprop="description">A free place</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/JasonVictor17" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;JasonVictor17" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jason</span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.0
  </div>
-->
<div class="powered-by">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <i class="fa fa-user-md"></i>
    <span id="busuanzi_container_site_uv">
        本站访客数:<span id="busuanzi_value_site_uv"></span>
    </span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_pv">
        本站访问量<span id="busuanzi_value_site_pv"></span>
    </span>
</div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">本博客全站共46.2k字</span>
</div>
        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>









<script>
if (document.querySelectorAll('div.pdf').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/pdfobject@2/pdfobject.min.js', () => {
    document.querySelectorAll('div.pdf').forEach(element => {
      PDFObject.embed(element.getAttribute('target'), element, {
        pdfOpenParams: {
          navpanes: 0,
          toolbar: 0,
          statusbar: 0,
          pagemode: 'thumbs',
          view: 'FitH'
        },
        PDFJS_URL: '/lib/pdf/web/viewer.html',
        height: element.getAttribute('height') || '500px'
      });
    });
  }, window.PDFObject);
}
</script>




  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

</body>
</html>
